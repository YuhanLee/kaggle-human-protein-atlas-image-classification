{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65KuEOQYX0oI"
   },
   "source": [
    "# Human Protein Atlas Image Classification\n",
    "\n",
    "\n",
    "Image classification of microscope slides based on mixed protein patterns.\n",
    "\n",
    "### Project Description\n",
    "The objective for this project is to determine the locations of protein organelles present in the microscope images. This breaks down into two parts: first, identifying the protein location (in general) from the image, and second,labelling each organelle within the protein.\n",
    "\n",
    "In particular we aim to build a model that can reliably make predictions even when the images contain a mixture of different cell types with different morphologies. \n",
    "\n",
    "### Task \n",
    "The problem is a a multi-label image classification task. Each image containing a mixture of different cell types must be predicted for each of the 27 labels. \n",
    "\n",
    "The training images that was provided by the kaggle competition includes a train_csv file that contains a list of image ids with the identified protein labels. \n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- keras\n",
    "- tensorflow\n",
    "- numpy\n",
    "- pydot\n",
    "- pandas\n",
    "- OpenCV (opencv-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "RjD80xLQX0oT",
    "outputId": "ce65eeed-4dc2-495b-aedc-87bc428f6b1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Input, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2                      # openCV image processing\n",
    "import pickle                   # object serialization\n",
    "import numpy as np              # linear algebra\n",
    "import pandas as pd             # data processing\n",
    "import pydot                    # graphing/visualization\n",
    "import matplotlib.pyplot as plt # graphing/visualization\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8IT9AOJX0os"
   },
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xCNdgSFX0ow"
   },
   "outputs": [],
   "source": [
    "NUCLEOPLASM                   = 0\n",
    "NUCLEAR_MEMBRANE              = 1\n",
    "NUCLEOLI                      = 2\n",
    "NUCLEOLI_FIBRILLAR_CENTER     = 3\n",
    "NUCLEAR_SPECKLES              = 4\n",
    "NUCLEAR_BODIES                = 5\n",
    "ENDOPLASMIC_RETICULUM         = 6\n",
    "GOLGI_APPARATUS               = 7\n",
    "PEROXISOMES                   = 8\n",
    "ENDOSOMES                     = 9\n",
    "LYSOSOMES                     = 10\n",
    "INTERMEDIATE_FILAMENTS        = 11\n",
    "ACTIN_FILAMENTS               = 12\n",
    "FOCAL_ADHESION_SITES          = 13\n",
    "MICROTUBULES                  = 14\n",
    "MICROTUBULE_ENDS              = 15\n",
    "CYTOKINETIC_BRIDGE            = 16\n",
    "MITOTIC_SPINDLE               = 17\n",
    "MICROTUBULE_ORGANIZING_CENTER = 18\n",
    "CENTROSOME                    = 19\n",
    "LIPID_DROPLETS                = 20\n",
    "PLASMA_MEMBRANE               = 21\n",
    "CELL_JUNCTIONS                = 22\n",
    "MITOCHONDRIA                  = 23\n",
    "AGGRESOME                     = 24\n",
    "CYTOSOL                       = 25\n",
    "CYTOPLASMIC_BODIES            = 26\n",
    "RODS_AND_RINGS                = 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cy6hSk4LX0o7"
   },
   "source": [
    "### Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8C04NDFX0pA"
   },
   "outputs": [],
   "source": [
    "LABELS_DIR = 'dataset'\n",
    "TRAIN_DIR = 'dataset/train'\n",
    "TEST_DIR = 'dataset/test'\n",
    "TRAIN_SUBSET_SIZE = 10 # Selection of images to train from (chosen at random, max size is 31072)\n",
    "LEN_LABELS = 28\n",
    "\n",
    "EPOCHS = 1 # epochs to train for (the more the better)\n",
    "INIT_LR = 1e-3 # initial learning rate for the solver\n",
    "BS = 32 # batch size\n",
    "IMG_SIZE = (512, 512, 1) # 512 by 512 pixels and only one channel (black and white)\n",
    "\n",
    "# random seed\n",
    "random.seed(56732)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AvfKbFHBX0pK"
   },
   "source": [
    "### Image Loading\n",
    "\n",
    "The first step is to take our dataset and prepare it so that it's ready for our model.\n",
    "\n",
    "Images are split into four filters/layers:\n",
    "- **green**: the protein of interest\n",
    "- **blue**: the nucleus\n",
    "- **red**: the microtubules\n",
    "- **yellow**: the endoplasmic reticulum\n",
    "\n",
    "For this project we will mostly be interested in the **green** filter, which will be used to predict the label, while the other filters will be used as references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "cq-iRTUlX0pN",
    "outputId": "cdc15b8e-dcea-44e7-b952-b4120c8a1439"
   },
   "outputs": [],
   "source": [
    "# Get images by layer\n",
    "\n",
    "# training set images\n",
    "train_green  = [(TRAIN_DIR+'/{}').format(i) for i in os.listdir(TRAIN_DIR) if 'green'  in i]\n",
    "\n",
    "# Select TRAIN_SUBSET_SIZE images from the training set at random\n",
    "random.shuffle(train_green)\n",
    "train_green = train_green[:TRAIN_SUBSET_SIZE]\n",
    "train_green_ids = [i[:-10].replace((TRAIN_DIR+'/'),'') \n",
    "                       for i in train_green] # remove '_green.png' and '_green.tif'\n",
    "\n",
    "# Retrieve the other three layers for our subset (NB: unsorted)\n",
    "train_blue =   [(TRAIN_DIR+'/{}').format(i) for i in os.listdir(TRAIN_DIR)\n",
    "                  if ((i[:-9] in train_green_ids) and ('blue' in i))]\n",
    "train_red =    [(TRAIN_DIR+'/{}').format(i) for i in os.listdir(TRAIN_DIR)\n",
    "                  if ((i[:-8] in train_green_ids) and ('red' in i))]\n",
    "train_yellow = [(TRAIN_DIR+'/{}').format(i) for i in os.listdir(TRAIN_DIR)\n",
    "                  if ((i[:-11] in train_green_ids) and ('yellow' in i))]\n",
    "\n",
    "# force garbage collection to make sure memory isn't wasted\n",
    "gc.collect()\n",
    "\n",
    "# test set images\n",
    "test_green  = [(TEST_DIR+'/{}').format(i) for i in os.listdir(TEST_DIR) if 'green'  in i]\n",
    "test_blue   = [(TEST_DIR+'/{}').format(i) for i in os.listdir(TEST_DIR) if 'blue'   in i]\n",
    "test_red    = [(TEST_DIR+'/{}').format(i) for i in os.listdir(TEST_DIR) if 'red'    in i]\n",
    "test_yellow = [(TEST_DIR+'/{}').format(i) for i in os.listdir(TEST_DIR) if 'yellow' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhGwPb54X0pV"
   },
   "outputs": [],
   "source": [
    "# Testing the above by seeing if the IDs are the same\n",
    "\n",
    "train_green.sort()\n",
    "train_blue.sort()\n",
    "train_red.sort()\n",
    "train_yellow.sort()\n",
    "#print(train_green, end='\\n\\n')\n",
    "#print(train_blue, end='\\n\\n')\n",
    "#print(train_red, end='\\n\\n')\n",
    "#print(train_yellow, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Train splitting\n",
    "\n",
    "Split the data from the train set into 80% training and 20% validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "# USE sklearn.model_selection import train_test_split FOR THIS PART\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXf6fgfVjvH0"
   },
   "source": [
    "### Label Loading\n",
    "\n",
    "Loading the labels from *train.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtNBfjMfjxV2"
   },
   "outputs": [],
   "source": [
    "train_labels = {} # dictionary with key = photo ID and entry = list of labels\n",
    "\n",
    "# Get all the labels\n",
    "with open('dataset/train.csv') as label_file:\n",
    "  csvreader = csv.reader(label_file, delimiter=',', quotechar='|')\n",
    "  for row in csvreader:\n",
    "    if \"Id\" not in row[0]:\n",
    "        # only take the ones that were taken in the Image Loading part\n",
    "        if any(row[0] in x for x in train_green):\n",
    "            train_labels[row[0]] = row[1:][0].split(' ') # labels are separated by spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8TTKKnnkewLO"
   },
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nhr-zmArr_Ag"
   },
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kV7Weri7sRWK"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(train_tags):\n",
    "    ''' Creates a one hot encoded dictionary of all labels for each pic'''\n",
    "    encoded = dict()\n",
    "  \n",
    "    for key in train_tags.keys():\n",
    "        # create empty vector\n",
    "        encoding = np.zeros(LEN_LABELS, dtype='uint8')\n",
    "        # mark 1 for each tag in the vector\n",
    "        for tag in train_tags[key]:\n",
    "            encoding[int(tag)] = 1\n",
    "            \n",
    "        encoded[key] = tuple(encoding)\n",
    "  \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Photo ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>09599842-bbc7-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1ec3408c-bbb5-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28bae982-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3e52503a-bbbc-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65e5fd08-bbb8-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8c3a68f4-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942ba3aa-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b0d9e2da-bbad-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>c01dd2ac-bba7-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f58cbdfa-bbb5-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0   1   2   3   4   5   6   7   8   9   \\\n",
       "Photo ID                                                                       \n",
       "09599842-bbc7-11e8-b2bc-ac1f6b6435d0   0   0   1   0   0   0   0   0   0   0   \n",
       "1ec3408c-bbb5-11e8-b2ba-ac1f6b6435d0   1   0   1   0   0   0   0   0   0   0   \n",
       "28bae982-bbc9-11e8-b2bc-ac1f6b6435d0   0   0   1   0   0   0   0   0   0   0   \n",
       "3e52503a-bbbc-11e8-b2ba-ac1f6b6435d0   0   0   0   1   0   0   0   0   0   0   \n",
       "65e5fd08-bbb8-11e8-b2ba-ac1f6b6435d0   0   0   1   0   0   1   0   0   0   0   \n",
       "8c3a68f4-bba4-11e8-b2b9-ac1f6b6435d0   1   0   1   0   0   0   0   0   0   0   \n",
       "942ba3aa-bb9c-11e8-b2b9-ac1f6b6435d0   1   0   0   0   0   0   0   0   0   0   \n",
       "b0d9e2da-bbad-11e8-b2ba-ac1f6b6435d0   1   0   0   0   0   0   0   0   0   0   \n",
       "c01dd2ac-bba7-11e8-b2ba-ac1f6b6435d0   1   0   1   0   0   0   0   0   0   0   \n",
       "f58cbdfa-bbb5-11e8-b2ba-ac1f6b6435d0   1   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "                                      ...  18  19  20  21  22  23  24  25  26  \\\n",
       "Photo ID                              ...                                       \n",
       "09599842-bbc7-11e8-b2bc-ac1f6b6435d0  ...   0   0   0   0   0   0   0   1   0   \n",
       "1ec3408c-bbb5-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   0   0   0   0   0   0   \n",
       "28bae982-bbc9-11e8-b2bc-ac1f6b6435d0  ...   0   0   0   0   0   0   0   0   0   \n",
       "3e52503a-bbbc-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   0   0   0   0   0   0   \n",
       "65e5fd08-bbb8-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   0   0   0   0   1   0   \n",
       "8c3a68f4-bba4-11e8-b2b9-ac1f6b6435d0  ...   0   0   0   0   0   0   0   0   0   \n",
       "942ba3aa-bb9c-11e8-b2b9-ac1f6b6435d0  ...   0   0   0   0   0   0   0   1   0   \n",
       "b0d9e2da-bbad-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   0   0   1   0   0   0   \n",
       "c01dd2ac-bba7-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   0   0   0   0   1   0   \n",
       "f58cbdfa-bbb5-11e8-b2ba-ac1f6b6435d0  ...   0   0   0   1   0   0   0   0   0   \n",
       "\n",
       "                                      27  \n",
       "Photo ID                                  \n",
       "09599842-bbc7-11e8-b2bc-ac1f6b6435d0   0  \n",
       "1ec3408c-bbb5-11e8-b2ba-ac1f6b6435d0   0  \n",
       "28bae982-bbc9-11e8-b2bc-ac1f6b6435d0   0  \n",
       "3e52503a-bbbc-11e8-b2ba-ac1f6b6435d0   0  \n",
       "65e5fd08-bbb8-11e8-b2ba-ac1f6b6435d0   0  \n",
       "8c3a68f4-bba4-11e8-b2b9-ac1f6b6435d0   0  \n",
       "942ba3aa-bb9c-11e8-b2b9-ac1f6b6435d0   0  \n",
       "b0d9e2da-bbad-11e8-b2ba-ac1f6b6435d0   0  \n",
       "c01dd2ac-bba7-11e8-b2ba-ac1f6b6435d0   0  \n",
       "f58cbdfa-bbb5-11e8-b2ba-ac1f6b6435d0   0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_labels = one_hot_encode(train_labels)\n",
    "training_set = pd.DataFrame.from_dict(ohe_labels, orient='index')\n",
    "training_set.index.name = \"Photo ID\"\n",
    "training_set.reset_index()\n",
    "training_set.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Visualization (using matplotlib)\n",
    "\n",
    "As we can see the training set is highly imbalanced.\n",
    "This may be indicative of the rarity of certain protein types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e7ece66470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# If this gives a boring graph, increase the subset size to look at more features.\n",
    "training_set.astype(bool).sum(axis=0).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "(see https://keras.io/preprocessing/image/)\n",
    "\n",
    "This will provide real-time data augmentation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "              height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "              horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Process (into Keras-ready train and test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Keras and OpenCV docs\n",
    "\n",
    "def read_and_process(images_paths, ohe_dataframe):\n",
    "    '''\n",
    "    takes a panda dataframe with rows as picture IDs and columns as labels\n",
    "    returns lists for keras (to be used as x and y inputs to the CNN)\n",
    "    '''\n",
    "\n",
    "    images = [] # will be used by keras as x\n",
    "    labels = [] # will be used by keras as y\n",
    "\n",
    "    for img in images_paths:\n",
    "        # build image list using img_to_array() and OpenCV\n",
    "        images.append(img_to_array(cv2.imread(img, cv2.IMREAD_GRAYSCALE))) # load images using cv2.imread()\n",
    "\n",
    "        # build labels/target/tag list\n",
    "        # Check labels at each step and build labels list accordingly\n",
    "        # --> order is important, the lists are meant to be zip()ed\n",
    "        for idx, row in ohe_dataframe.iterrows():\n",
    "            if idx in img:\n",
    "                labels.append(tuple(row))\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = read_and_process(train_green, training_set)\n",
    "# test_x,  test_y  = read_and_process(validation_green, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Setup\n",
    "\n",
    "Now that the preprocessing is out of the way, we can build our CNN structure.\n",
    "\n",
    "This will be an implementation of *SmallerVGGNet*, as described here: https://arxiv.org/pdf/1409.1556/\n",
    "\n",
    "#### Input Layer\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "height, width, depth = IMG_SIZE\n",
    "input_shape = (height, width, depth) # derived from image size\n",
    "chanDim = -1\n",
    "classes = LEN_LABELS # number of classification classes\n",
    "\n",
    "# if we are using \"channels first\", update the input shape\n",
    "# and channels dimension\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    input_shape = (depth, height, width)\n",
    "    chanDim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv + ReLU + Pool Blocks\n",
    "\n",
    "Increasing filter sizes help increase depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First CONV => RELU => POOL block\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape)) # 32 filters and a 3x3 kernel\n",
    "model.add(Activation(\"relu\")) # standard activation layer\n",
    "model.add(BatchNormalization(axis=chanDim)) # normalize all inputs to the [0, 1] range\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25)) # dropout will reduce overfitting by randomly dropping 25% of nodes\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL (first double convolution before pooling)\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\")) # 64 filters and 3x3 kernel\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # smaller pool size this time to reduce spatial size\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU) * 2 => POOL (second double convolution before pooling)\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\")) # 128 filters and 3x3 kernel\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected + ReLU block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first (and only) set of FC => RELU layers\n",
    "model.add(Flatten()) # Collapses the spatial dimensions of the input into the channel dimensions\n",
    "model.add(Dense(1024)) # dense layer of neurons with 1024 being the dimensionality of the output space\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) # Dropout of 50%\n",
    "\n",
    "# Since this is multi-label classification we use the sigmoid activation function\n",
    "model.add(Dense(classes)) # output dimensionality equal to the number of output classes\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##I think we want \"softmax\" not sigmoid, any picture may be multiple 1's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # clip predictions\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate elements\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score\n",
    " \n",
    "    \n",
    "    \n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    #pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision = true positives / (true positives + false positives)\n",
    "#recall = true positives / (true positives + false negatives)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "protein_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
